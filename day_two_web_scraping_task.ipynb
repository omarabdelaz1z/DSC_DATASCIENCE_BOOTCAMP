{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = {\n",
    "    'politics': 78,\n",
    "    'accidents': 7,\n",
    "    'sports': 8,\n",
    "    'economics': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Article URLs\n",
    "Assuming we are interested in Sport, Politics, Accidents and Economics Articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_urls(article_id, page):\n",
    "    \"\"\"\n",
    "    Given article_id and page number, we fetch all the articles' urls in that page.\n",
    "    returns List of urls.\n",
    "    \"\"\"\n",
    "    url = 'https://www.almasryalyoum.com/news/index?page=' + str(page) + '&sectionid=' + str(article_id) + '&typeid=1'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if not response.ok:\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        list_of_news = soup.find('div', attrs={'class':'ListNews'}).findAll('div', attrs = {'class':'news'})\n",
    "        \n",
    "        article_urls = []\n",
    "        for news in list_of_news:\n",
    "            article_urls.append('https://www.almasryalyoum.com' + news.find('a')['href'])\n",
    "        \n",
    "        if not article_urls: \n",
    "            return False\n",
    "        \n",
    "        return article_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Article Details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_details(url):\n",
    "    \"\"\"\n",
    "    Returning various information of an article.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    news_title = soup.title.text\n",
    "    news_image = soup.find('div', attrs= {'class':'articleimg'}).find('img')['src']\n",
    "    body = soup.find('div',attrs={'id':'NewsStory'})\n",
    "    \n",
    "    # removing unraleted text\n",
    "    body.find('div',attrs={'class':'smsBoxContainer-v1'}).decompose()\n",
    "    body.find('div',attrs={'class':'min_related'}).decompose()\n",
    "    \n",
    "    news_body = \"\"\n",
    "    for p in body.findAll('p'):\n",
    "        news_body += \" \" + p.text\n",
    "     \n",
    "    news_keywords = soup.find('meta',attrs={'name':'keywords'})['content']    \n",
    "    \n",
    "    news_article = {\n",
    "        'news_url': url,\n",
    "        'news_title': news_title,\n",
    "        'news_image':news_image,\n",
    "        'news_body': news_body,\n",
    "        'news_keywords': news_keywords\n",
    "    }\n",
    "    \n",
    "    return news_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function return a pandas DataFrame of all news of a specific section/page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(article_id = 8, page = 2):\n",
    "    \"\"\"\n",
    "    Return a pandas DataFrame of all news/articles in a specific page.\n",
    "    \"\"\"\n",
    "    topic_articles = []\n",
    "    urls = get_articles_urls(article_id, page)\n",
    "    \n",
    "    if hasattr(urls, '__iter__'):\n",
    "        for url in get_articles_urls(article_id, page):\n",
    "            topic_articles.append(get_article_details(url))\n",
    "    \n",
    "        return pd.DataFrame(topic_articles)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_articles = get_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sports_articles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
